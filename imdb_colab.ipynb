{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NVZYcW59OrzU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"IMDB Dataset.csv\", engine='python', on_bad_lines='skip', quotechar='\"', escapechar='\\\\')\n",
        "print(df.shape)\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "EkyIovvtPKoU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c515f3b4-4efd-4c38-e0ce-b7632a627b09"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 2)\n",
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'<.*?>', '', text)  # remove HTML tags\n",
        "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
        "    return text\n",
        "\n",
        "df['cleaned'] = df['review'].apply(clean_text)\n",
        "df['label'] = df['sentiment'].map({'positive':1, 'negative':0})"
      ],
      "metadata": {
        "id": "UC13IlCkRP4I"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build vocabulary from training text\n",
        "all_words = ' '.join(df['cleaned']).split()\n",
        "counts = Counter(all_words)\n",
        "MAX_VOCAB = 20000\n",
        "vocab_list = [w for w,_ in counts.most_common(MAX_VOCAB)]\n",
        "vocab = {w:i+1 for i,w in enumerate(vocab_list)}  # index 0 = padding\n",
        "\n",
        "def encode(text):\n",
        "    return [vocab.get(w, 0) for w in text.split()]\n",
        "\n",
        "df['encoded'] = df['cleaned'].apply(encode)\n"
      ],
      "metadata": {
        "id": "U4JRQKoQS9cr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "MAX_LEN = 200\n",
        "def pad(seq, max_len=MAX_LEN):\n",
        "    return seq[:max_len] + [0]*(max_len-len(seq))\n",
        "\n",
        "df['padded'] = df['encoded'].apply(lambda x: pad(x, MAX_LEN))\n",
        "\n",
        "X = np.array(df['padded'].tolist())\n",
        "y = df['label'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "wD9nKEwjTCW2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.long)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32)\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_ds = IMDBDataset(X_train, y_train)\n",
        "test_ds = IMDBDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(test_ds, batch_size=128)"
      ],
      "metadata": {
        "id": "bwYXToA3SPFQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SentimentLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=128, output_dim=1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size+1, embed_dim)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        out, (h, c) = self.lstm(x)\n",
        "        h = self.dropout(h[-1])  # last layer hidden state\n",
        "        out = self.fc(h)\n",
        "        return self.sigmoid(out)"
      ],
      "metadata": {
        "id": "zDjUO7Q9TLsU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = SentimentLSTM(len(vocab)).to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "EPOCHS = 10\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(X_batch).squeeze()\n",
        "        loss = criterion(preds, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f40-zB-9TOTT",
        "outputId": "a20d02df-62d4-45ce-a488-fb4934a213ef"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.6936\n",
            "Epoch 2, Loss: 0.6845\n",
            "Epoch 3, Loss: 0.6779\n",
            "Epoch 4, Loss: 0.6719\n",
            "Epoch 5, Loss: 0.5142\n",
            "Epoch 6, Loss: 0.3540\n",
            "Epoch 7, Loss: 0.2666\n",
            "Epoch 8, Loss: 0.2185\n",
            "Epoch 9, Loss: 0.1763\n",
            "Epoch 10, Loss: 0.1397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        preds = model(X_batch).squeeze()\n",
        "        preds = (preds.cpu().numpy() > 0.5).astype(int)\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(y_batch.numpy())\n",
        "\n",
        "acc = accuracy_score(all_labels, all_preds)\n",
        "print(\"Test Accuracy:\", acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6A-Or_H7TRt_",
        "outputId": "ddd98e21-1910-4c56-c40c-87763001d557"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------- Manual prediction with custom review ---------\n",
        "\n",
        "test_sentence = \"The service was terrible, the food was cold, and I will never come back here again.\"\n",
        "\n",
        "# Same cleaning as training\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"<.*?>\", \"\", text)\n",
        "    text = re.sub(r\"[^a-zA-Z]\", \" \", text)\n",
        "    return text\n",
        "\n",
        "def encode(text, vocab):\n",
        "    return [vocab.get(w, 0) for w in text.split()]\n",
        "\n",
        "def pad(seq, max_len=200):\n",
        "    return seq[:max_len] + [0]*(max_len-len(seq))"
      ],
      "metadata": {
        "id": "Z1N77qFwTaia"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess this single input\n",
        "cleaned = clean_text(test_sentence)\n",
        "encoded = encode(cleaned, vocab)\n",
        "padded = pad(encoded)\n",
        "\n",
        "# Convert to tensor and send to same device\n",
        "tensor = torch.tensor([padded], dtype=torch.long).to(device)\n",
        "\n",
        "# Predict\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    pred = model(tensor)\n",
        "    score = pred.item()\n",
        "    label = \"Positive\" if score > 0.5 else \"Negative\"\n",
        "\n",
        "print(\"Input review:\", test_sentence)\n",
        "print(f\"Prediction: {label} (confidence={score:.4f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0uTrbSBT1wr",
        "outputId": "4a6ed2c1-9b63-4133-ea51-8092d57be10a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input review: The service was terrible, the food was cold, and I will never come back here again.\n",
            "Prediction: Negative (confidence=0.0118)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"imdb_lstm_model.pth\")\n",
        "import pickle\n",
        "pickle.dump(vocab, open(\"vocab.pkl\",\"wb\"))"
      ],
      "metadata": {
        "id": "nGw0DL10T2wX"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hsy7H-S3T9qh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}